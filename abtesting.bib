@misc{Antony2006,
abstract = {Taguchi or classical design of experiments: a perspective from a practitioner},
author = {Antony, Jiju},
booktitle = {Sensor Review},
doi = {10.1108/02602280610675519},
issn = {0260-2288},
pages = {227--230},
title = {{Taguchi or classical design of experiments: a perspective from a practitioner}},
volume = {26},
year = {2006}
}
@misc{Ashkenas2012,
author = {Ashkenas, J. and Ericson, M. and Parlapiano, A. and Willis, D.},
booktitle = {The New York Times},
title = {{The 2012 Money Race: Compare the Candidates}},
url = {http://elections.nytimes.com/2012/campaign-finance},
urldate = {26.10.2014},
year = {2012}
}
@misc{Berners-Lee2001,
abstract = {A new form of Web content that is meaningful to computers will unleash a revolution of new possibilities.},
archivePrefix = {arXiv},
arxivId = {1204.6441},
author = {Berners-Lee, Tim and Hendler, James and Lassila, Ora},
booktitle = {Scientific American},
eprint = {1204.6441},
issn = {0036-8733},
number = {5},
pages = {34--43},
pmid = {122},
title = {{The Semantic Web}},
volume = {284},
year = {2001}
}
@inproceedings{Chang2006,
abstract = {Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers. Many projects at Google store data in Bigtable, including web indexing, Google Earth, and Google Fi- nance. These applications place very different demands on Bigtable, both in terms of data size (from URLs to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving). Despite these varied demands, Bigtable has successfully provided a flexible, high-performance solution for all of these Google products. In this paper we describe the sim- ple data model provided by Bigtable, which gives clients dynamic control over data layout and format, and we de- scribe the design and implementation of Bigtable.},
author = {Chang, Fay and Dean, Jeffrey and Ghemawat, Sanjay and Hsieh, Wilson C. and Wallach, Deborah A. and Burrows, Mike and Chandra, Tushar and Fikes, Andrew and Gruber, Robert E.},
booktitle = {7th Symposium on Operating Systems Design and Implementation (OSDI '06), November 6-8, Seattle, WA, USA},
pages = {205--218},
publisher = {USENIX Association},
title = {{Bigtable: A distributed storage system for structured data}},
url = {http://research.google.com/archive/bigtable-osdi06.pdf},
year = {2006}
}
@misc{Chopra2012,
abstract = {A/B testing isn’t a buzz term. A lot of savvy marketers and designs are using it right now to gain insight into visitor behavior and to increase conversion rate. And yet A/B testing is still not as common as such Internet marketing subjects as SEO, Web analytics and usability. People just aren’t as aware of it. They don’t completely understand what it is or how it could benefit them or how they should use it. This article is meant to be the best guide you will ever need for A/B testing.},
author = {Chopra, Paras},
booktitle = {Smashing Magazine},
title = {{The Ultimate Guide To A/B Testing}},
url = {http://www.smashingmagazine.com/2010/06/24/the-ultimate-guide-to-a-b-testing/},
year = {2012}
}
@misc{Collins2014,
author = {Collins, Steve},
booktitle = {GDC Vault},
title = {{A/B Testing for Game Design Iteration: A Bayesian Approach}},
url = {http://www.gdcvault.com/play/1020201/A-B-Testing-for-Game},
urldate = {2.11.2014},
year = {2014}
}
@article{Comput2005,
abstract = {Neural networks have been widely used in manufacturing industry, but they suffer from a lack of structured method to determine the settings of NN design and training parameters, which are usually set by trial and error. This article presents an application of Taguchis Design of Experiments, to identify the optimum setting of NN parameters in a multilayer perceptron (MLP) network trained with the back propagation algorithm. A case study of a complex forming process is used to demonstrate implementation of the approach in manufacturing, and the issues arising from the case are discussed.},
author = {Comput, Neural},
doi = {10.1007/s00521-005-0470-3},
issn = {09410643},
journal = {Neural Computation},
keywords = {manufacturing process,neural networks \ae taguchi,\ae doe \ae},
pages = {337--344},
title = {{The optimisation of neural network parameters using Taguchi ’ s design of experiments approach : an application in manufacturing process modelling}},
volume = {14},
year = {2005}
}
@article{Crawford1990,
abstract = {Misrepresentation in research is clearly a problem today. In the environment of big science, with accelerating competition, increased rewards for discovery and uncertainties of long-range outcome, two important checks on quality control - peer review and the replication of results - are more difficult to accomplish effectively. Additionally, the new information technology now enables scientists to communicate outside established channels where their work is judged. However, it is argued that science is a self-correcting system and errors that are inadvertent or deliberate will be corrected over time. copyright 1990 John Wiley \& Sons, Inc.},
author = {Crawford, Susan and Stucki, Loretta},
doi = {10.1002/(SICI)1097-4571(199004)41:3\%3C223::AID-ASI14\%3E3.0.CO;2-3},
issn = {10974571},
journal = {Journal of the American Society for Information Science},
pages = {223--228},
title = {{Peer review and the changing research record}},
url = {http://www3.interscience.wiley.com/cgi-bin/abstract/10049557/ABSTRACT},
volume = {41},
year = {1990}
}
@misc{Ghemawat2003,
abstract = {We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients. While sharing many of the same goals as previous distributed file systems, our design has been driven by observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore radically different design points. The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients. In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.},
author = {Ghemawat, Sanjay and Gobioff, Howard and Leung, Shun-Tak},
booktitle = {ACM SIGOPS Operating Systems Review},
issn = {01635980},
number = {5},
pages = {29},
pmid = {191},
title = {{The Google file system}},
volume = {37},
year = {2003}
}
@misc{Heggenstuen2013,
author = {Heggenstuen, John},
booktitle = {Business Insider},
title = {{One In Every 5 People In The World Own A Smartphone, One In Every 17 Own A Tablet}},
url = {http://www.businessinsider.com/smartphone-and-tablet-penetration-2013-10},
year = {2013}
}
@article{Hevner2004,
abstract = {Two paradigms characterize much of the research in the Information Systems discipline: behavioral science and design science. The behavioral science paradigm seeks to develop and verify theories that explain or predict human or organizational behavior. The design-science paradigm seeks to extend the boundaries of human and organizational capabilities by creating new and innovative artifacts. Both paradigms are foundational to the IS discipline, positioned as it is at the confluence of people, organizations, and technology. Our objective is to describe the performance of design-science research in Information Systems via a concise conceptual framework and clear guidelines for understanding, executing, and evaluating the research. In the design-science paradigm, knowledge and understanding of a problem domain and its solution are achieved in the building and application of the designed artifact. Three recent exemplars in the research literature are used to demonstrate the application of these guidelines. We conclude with an analysis of the challenges of performing high-quality design-science research in the context of the broader IS community.},
archivePrefix = {arXiv},
arxivId = {http://dl.acm.org/citation.cfm?id=2017212.2017217},
author = {Hevner, Alan R and March, Salvatore T and Park, Jinsoo and Ram, Sudha},
doi = {10.2307/25148625},
eprint = {/dl.acm.org/citation.cfm?id=2017212.2017217},
isbn = {0276-7783},
issn = {02767783},
journal = {MIS Quarterly},
keywords = {Information Systems research methodologies,business environment,creativity,design artifact,design science,experimental methods,search strategies,technology infrastructure},
pages = {75--105},
pmid = {12581935},
primaryClass = {http:},
title = {{Design Science in Information Systems Research}},
url = {http://dblp.uni-trier.de/rec/bibtex/journals/misq/HevnerMPR04},
volume = {28},
year = {2004}
}
@misc{Katkoff2013,
author = {Katkoff, Michail},
booktitle = {Deconstructor of Fun},
pages = {1},
title = {{Behind the success of Hay Day}},
urldate = {2.11.2014},
year = {2013}
}
@article{Kohavi2009,
abstract = {The web provides an unprecedented opportunity to evaluate ideas quickly using controlled experiments, also called randomized experiments, A/B tests (and their generalizations), split tests, Control/Treatment tests, MultiVariable Tests (MVT) and parallel flights. Controlled experiments embody the best scientific design for establishing a causal relationship between changes and their influence on user-observable behavior. We provide a practical guide to conducting online experiments, where end-users can help guide the development of features. Our experience indicates that significant learning and return-on-investment (ROI) are seen when development teams listen to their customers, not to the Highest Paid Person’s Opinion (HiPPO). We provide several examples of controlled experiments with surprising results. We review the important ingredients of running controlled experiments, and discuss their limitations (both technical and organizational). We focus on several areas that are critical to experimentation, including statistical power, sample size, and techniques for variance reduction. We describe common architectures for experimentation systems and analyze their advantages and disadvantages. We evaluate randomization and hashing techniques, which we show are not as simple in practice as is often assumed. Controlled experiments typically generate large amounts of data, which can be analyzed using data mining techniques to gain deeper understanding of the factors influencing the outcome of interest, leading to new hypotheses and creating a virtuous cycle of improvements. Organizations that embrace controlled experiments with clear evaluation criteria can evolve their systems with automated optimizations and real-time analyses. Based on our extensive practical experience with multiple systems and organizations, we share key lessons that will help practitioners in running trustworthy controlled experiments.},
author = {Kohavi, Ron and Longbotham, Roger},
doi = {10.1007/s10618-008-0114-1},
issn = {1384-5810},
journal = {Data Mining and \ldots},
pages = {140--181},
title = {{Controlled experiments on the web: survey and practical guide}},
url = {http://link.springer.com/10.1007/s10618-008-0114-1$\backslash$nhttp://link.springer.com/article/10.1007/s10618-008-0114-1},
volume = {18},
year = {2009}
}
@article{Kohavi2009a,
abstract = {The web provides an unprecedented opportunity to evaluate ideas quickly using controlled experiments, also called randomized experiments, A/B tests (and their generalizations), split tests, Control/Treatment tests, MultiVariable Tests (MVT) and parallel flights. Controlled experiments embody the best scientific design for establishing a causal relationship between changes and their influence on user-observable behavior. We provide a practical guide to conducting online experiments, where end-users can help guide the development of features. Our experience indicates that significant learning and return-on-investment (ROI) are seen when development teams listen to their customers, not to the Highest Paid Person’s Opinion (HiPPO). We provide several examples of controlled experiments with surprising results. We review the important ingredients of running controlled experiments, and discuss their limitations (both technical and organizational). We focus on several areas that are critical to experimentation, including statistical power, sample size, and techniques for variance reduction. We describe common architectures for experimentation systems and analyze their advantages and disadvantages. We evaluate randomization and hashing techniques, which we show are not as simple in practice as is often assumed. Controlled experiments typically generate large amounts of data, which can be analyzed using data mining techniques to gain deeper understanding of the factors influencing the outcome of interest, leading to new hypotheses and creating a virtuous cycle of improvements. Organizations that embrace controlled experiments with clear evaluation criteria can evolve their systems with automated optimizations and real-time analyses. Based on our extensive practical experience with multiple systems and organizations, we share key lessons that will help practitioners in running trustworthy controlled experiments.},
author = {Kohavi, Ron and Longbotham, Roger},
doi = {10.1007/s10618-008-0114-1},
issn = {1384-5810},
journal = {Data Mining and \ldots},
pages = {140--181},
title = {{Controlled experiments on the web: survey and practical guide}},
url = {http://link.springer.com/10.1007/s10618-008-0114-1$\backslash$nhttp://link.springer.com/article/10.1007/s10618-008-0114-1},
volume = {18},
year = {2009}
}
@misc{Kohavi2004,
author = {Kohavi, Ron and Round, Matt},
file = {:Users/sulmanen/Library/Application Support/Mendeley Desktop/Downloaded/Kohavi, Round - 2004 - Front Line Internet Analytics at Amazon.com.pdf:pdf},
title = {{Front Line Internet Analytics at Amazon.com}},
url = {http://ai.stanford.edu/~ronnyk/emetricsAmazon.pdf},
year = {2004}
}
@book{Laininen1998,
author = {Laininen, Pertti},
isbn = {951-672-279-2},
pages = {308},
publisher = {Otatieto},
title = {{Todenn\"{a}k\"{o}isyys ja sen Tilastollinen Soveltaminen}},
year = {1998}
}
@article{Liu2014,
author = {Liu, Alex},
file = {:Users/sulmanen/Library/Application Support/Mendeley Desktop/Downloaded/Liu - 2014 - JavaScript and the Netflix User Interface Conditional dependency resolution.pdf:pdf},
journal = {acmqueue},
keywords = {abtesting,javascript,netflix,ui},
pages = {1--13},
title = {{JavaScript and the Netflix User Interface Conditional dependency resolution}},
url = {http://delivery.acm.org/10.1145/2680000/2677720/p20-liu.pdf?ip=86.50.146.151\&id=2677720\&acc=OPEN\&key=4D4702B0C3E38B35.4D4702B0C3E38B35.4D4702B0C3E38B35.6D218144511F3437\&CFID=593807020\&CFTOKEN=49212945\&\_\_acm\_\_=1414938888\_3981a4dc7e6909f9608ca83bcfb43063},
year = {2014}
}
@article{Mellick2009,
abstract = {The article focuses on the works and achievements of James Lind, James Cook and Owen Stanley. He traveled and worked on several countries as physician, promoted the use of cinchona bark to treat malaria and favoured the use of high-protein diet to maintain health. Cook made an outstanding Endeavour voyage without a single death of his crew over the two years and nine months journey. Stanley was responsible in completing Cook's map on his voyage from Sydney, north to Torres Strait and New Guinea.},
author = {Mellick, Sam A},
isbn = {14451433},
issn = {14452197},
journal = {ANZ journal of surgery},
pages = {936--940},
pmid = {20002999},
title = {{Signal naval achievements of James Lind (1747), James Cook (1770) and Owen Stanley (1847).}},
volume = {79},
year = {2009}
}
@unpublished{Oracle2012,
author = {Oracle},
file = {:Users/sulmanen/Library/Application Support/Mendeley Desktop/Downloaded/Oracle - 2012 - Using Social Gaming to Drive Engagement Insights and Best Practices for Brand Managers.pdf:pdf},
number = {August},
title = {{Using Social Gaming to Drive Engagement : Insights and Best Practices for Brand Managers}},
year = {2012}
}
@misc{Reichheld2003,
abstract = {Companies spend lots of time and money on complex tools to assess customer satisfaction. But they're measuring the wrong thing. The best predictor of top-line growth can usually be captured in a single survey question: Would you recommend this company to a friend? This finding is based on two years of research in which a variety of survey questions were tested by linking the responses with actual customer behavior--purchasing patterns and referrals--and ultimately with company growth. Surprisingly, the most effective question wasn't about customer satisfaction or even loyalty per se. In most of the industries studied, the percentage of customers enthusiastic enough about a company to refer it to a friend or colleague directly correlated with growth rates among competitors. Willingness to talk up a company or product to friends, family, and colleagues is one of the best indicators of loyalty because of the customer's sacrifice in making the recommendation. When customers act as references, they do more than indicate they've received good economic value from a company; they put their own reputations on the line. And they will risk their reputations only if they feel intense loyalty. The findings point to a new, simpler approach to customer research, one directly linked to a company's results. By substituting a single question--blunt tool though it may appear to be--for the complex black box of the customer satisfaction survey, companies can actually put consumer survey results to use and focus employees on the task of stimulating growth.},
author = {Reichheld, Frederick F.},
booktitle = {Harvard Business Review},
doi = {10.1111/j.1467-8616.2008.00516.x},
isbn = {00178012},
issn = {00178012},
pages = {46--54+124},
pmid = {14712543},
title = {{The One Number You Need to Grow}},
volume = {81},
year = {2003}
}
@book{Seufert2014,
abstract = {This chapter, “Growth,” explores all means by which a freemium product can expand its user base. The chapter begins with an introduction to strategic growth, which is a data-driven approach to optimizing a product’s reach through market research, and the degree to which users are retained in the earliest stages of product interaction. This retention focus is often accomplished with the onboarding funnel (sometimes called the tutorial funnel); onboarding is a highly analytical, highly granular process to ensure that the first few minutes of a user’s introduction to a product are optimized for retention. The chapter then leads to a discussion on paid user acquisition, which is the means by which a product is advertised. This section outlines the various components of an advertising system: the advertising exchange, the supply-side platform, and the demand-side platform. Paid search is also described in detail. The chapter concludes with a description of alternative user acquisition techniques and the means by which they are employed in freemium products. Alternative user acquisition encompasses traditional media advertising, search engine optimization, and the three forms of non-paid user acquisition: discovery, cross-promotion, and virality.},
author = {Seufert, Eric Benjamin},
booktitle = {Freemium Economics},
doi = {10.1016/B978-0-12-416690-5.00008-7},
isbn = {9780124166905},
keywords = {advertising exchanges,cross-promotion,demand-side platforms,demographic selection,discovery,mobile user acquisition,paid search,paid user acquisition,supply-side platforms,tutorial funnel,user onboarding,virality},
pages = {199--225},
title = {{Freemium Economics}},
url = {http://www.sciencedirect.com/science/article/pii/B9780124166905000087},
year = {2014}
}
@book{Siroker2013,
author = {Siroker, Dan and Koomen, Pete},
isbn = {978-1-118-53609-4},
keywords = {abtesting},
mendeley-tags = {abtesting},
pages = {208},
publisher = {John Wiley \& Sons},
title = {{A/B Testing: The Most Powerful Way to Turn Clicks Into Customers}},
year = {2013}
}
@misc{Snowden2007,
abstract = {First written by Dave Snowden as a seven-part series in his blog, this document outlines the origins and development of the Cynefin Framework over many years.},
author = {Snowden, David},
booktitle = {Context},
pages = {1--17},
title = {{The origins of cynefin}},
year = {2007}
}
@article{Vairis2009,
abstract = {Identification of significant process parameters using experiments needs to be carefully formulated as it can be a resource demanding process. Using appropriate statistical techniques such as the Taguchi method of factorial design of experiments, the number of necessary experiments can be reduced and the statistical significance of parameters can be safely identified. In the case of linear friction welding it was found that the frequency of oscillation, power input and forging pressure are statistically insignificant for the range of friction pressures studied.},
author = {Vairis, A. and Petousis, M.},
file = {:Users/sulmanen/Library/Application Support/Mendeley Desktop/Downloaded/Vairis, Petousis - 2009 - Designing experiments to study welding processes Using the taguchi method.pdf:pdf},
issn = {17919320},
journal = {Journal of Engineering Science and Technology Review},
keywords = {Factorial design of experiments,Friction welding,Taguchi method},
pages = {99--103},
title = {{Designing experiments to study welding processes: Using the taguchi method}},
volume = {2},
year = {2009}
}
@misc{VanBeurden2013,
abstract = {Health promotion addresses issues from the simple (with well-known cause/effect links) to the highly complex (webs and loops of cause/effect with unpredictable, emergent properties). Yet there is no conceptual framework within its theory base to help identify approaches appropriate to the level of complexity. The default approach favours reductionism--the assumption that reducing a system to its parts will inform whole system behaviour. Such an approach can yield useful knowledge, yet is inadequate where issues have multiple interacting causes, such as social determinants of health. To address complex issues, there is a need for a conceptual framework that helps choose action that is appropriate to context. This paper presents the Cynefin Framework, informed by complexity science--the study of Complex Adaptive Systems (CAS). It introduces key CAS concepts and reviews the emergence and implications of 'complex' approaches within health promotion. It explains the framework and its use with examples from contemporary practice, and sets it within the context of related bodies of health promotion theory. The Cynefin Framework, especially when used as a sense-making tool, can help practitioners understand the complexity of issues, identify appropriate strategies and avoid the pitfalls of applying reductionist approaches to complex situations. The urgency to address critical issues such as climate change and the social determinants of health calls for us to engage with complexity science. The Cynefin Framework helps practitioners make the shift, and enables those already engaged in complex approaches to communicate the value and meaning of their work in a system that privileges reductionist approaches.},
author = {{Van Beurden}, Eric K. and Kia, Annie M. and Zask, Avigdor and Dietrich, Uta and Rose, Lauren},
booktitle = {Health Promotion International},
doi = {10.1093/heapro/dar089},
isbn = {1460-2245 (Electronic)$\backslash$r0957-4824 (Linking)},
issn = {09574824},
keywords = {determinants of health,evidence-based health promotion,health promotion discourse,systems thinking},
pages = {73--83},
pmid = {22128193},
title = {{Making sense in a complex landscape: How the cynefin framework from complex adaptive systems theory can inform health promotion practice}},
volume = {28},
year = {2013}
}
@misc{VanBeurden2013a,
abstract = {Health promotion addresses issues from the simple (with well-known cause/effect links) to the highly complex (webs and loops of cause/effect with unpredictable, emergent properties). Yet there is no conceptual framework within its theory base to help identify approaches appropriate to the level of complexity. The default approach favours reductionism--the assumption that reducing a system to its parts will inform whole system behaviour. Such an approach can yield useful knowledge, yet is inadequate where issues have multiple interacting causes, such as social determinants of health. To address complex issues, there is a need for a conceptual framework that helps choose action that is appropriate to context. This paper presents the Cynefin Framework, informed by complexity science--the study of Complex Adaptive Systems (CAS). It introduces key CAS concepts and reviews the emergence and implications of 'complex' approaches within health promotion. It explains the framework and its use with examples from contemporary practice, and sets it within the context of related bodies of health promotion theory. The Cynefin Framework, especially when used as a sense-making tool, can help practitioners understand the complexity of issues, identify appropriate strategies and avoid the pitfalls of applying reductionist approaches to complex situations. The urgency to address critical issues such as climate change and the social determinants of health calls for us to engage with complexity science. The Cynefin Framework helps practitioners make the shift, and enables those already engaged in complex approaches to communicate the value and meaning of their work in a system that privileges reductionist approaches.},
author = {{Van Beurden}, Eric K. and Kia, Annie M. and Zask, Avigdor and Dietrich, Uta and Rose, Lauren},
booktitle = {Health Promotion International},
doi = {10.1093/heapro/dar089},
isbn = {1460-2245 (Electronic)$\backslash$r0957-4824 (Linking)},
issn = {09574824},
keywords = {determinants of health,evidence-based health promotion,health promotion discourse,systems thinking},
pages = {73--83},
pmid = {22128193},
title = {{Making sense in a complex landscape: How the cynefin framework from complex adaptive systems theory can inform health promotion practice}},
volume = {28},
year = {2013}
}
@inproceedings{Venable2010,
abstract = {There is ongoing debate about how the quality (rigour and relevance) of Design Science Research (DSR) should be judged. This research investigates the state of the debate by surveying the opinions of IS scholars who write, review, edit, and publish DSR papers. The survey respondents rated the relative importance of the seven guidelines (often used as evaluation criteria) laid out in Hevner et al. (2004) [6], more specific criteria about the evaluation activity in DSR, criteria concerning IS Design Theories, and miscellaneous other criteria, and made general open-ended comments. The findings indicate a lack of consensus, with much variability in ratings. The Hevner et al. [6] guidelines are largely endorsed, but caution is also raised to apply them less mechanistically than at present. Some criteria/guidelines are seen to be less important at earlier stages of research. Caution is also urged not to expect single papers to fit all criteria/guidelines.},
author = {Venable, John R.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-13335-0\_8},
isbn = {3642133347},
issn = {03029743},
keywords = {Design Science Research,Evaluation,IS Design Theory,Research Method,Research Standards},
pages = {109--123},
title = {{Design science research post Hevner et al.: Criteria, standards, guidelines, and expectations}},
volume = {6105 LNCS},
year = {2010}
}
@article{Vertica2012,
author = {Vertica, H P},
file = {:Users/sulmanen/Library/Application Support/Mendeley Desktop/Downloaded/Vertica - 2012 - Supercell adopts HP Vertica Analytics Platform.pdf:pdf},
keywords = {4AA5-1042ENW,Analytic Database Management,Enterprise software,HP Vertica,HP Vertica Analytics Platform,IT case study,Supercell,agility,cloud deployment},
pages = {2012--2014},
title = {{Supercell adopts HP Vertica Analytics Platform}},
year = {2012}
}
@article{Williams2011,
abstract = {This paper describes emergent learning and situates it within learning networks and systems and the broader learning ecology of Web 2.0. It describes the nature of emergence and emergent learning and the conditions that enable emergent, self-organised learning to occur and to flourish. Specifically, it explores whether emergent learning can be validated and self-correcting and whether it is possible to link or integrate emergent and prescribed learning. It draws on complexity theory, communities of practice, and the notion of connectivism to develop some of the foundations for an analytic framework, for enabling and managing emergent learning and networks in which agents and systems co-evolve. It then examines specific cases of learning to test and further develop the analytic framework. The paper argues that although social networking media increase the potential range and scope for emergent learning exponentially, considerable effort is required to ensure an effective balance between openness and constraint. It is possible to manage the relationship between prescriptive and emergent learning, both of which need to be part of an integrated learning ecology.},
author = {Williams, Roy and Karousou, Regina and Mackness, Jenny},
file = {:Users/sulmanen/Library/Application Support/Mendeley Desktop/Downloaded/Williams, Karousou, Mackness - 2011 - Emergent learning and learning ecologies in Web 2.0.pdf:pdf},
isbn = {1492-3831},
issn = {14923831},
journal = {International Review of Research in Open and Distance Learning},
keywords = {Constraints,Emergent learning,Emergent learning networks,Learning ecologies,Prescriptive learning,Retrospective sense-making},
pages = {39--59},
title = {{Emergent learning and learning ecologies in Web 2.0}},
volume = {12},
year = {2011}
}
@misc{Wilson2006,
author = {Wilson, Fred},
booktitle = {AVC},
pages = {1},
title = {{The Freemium Business Model}},
url = {http://avc.com/2006/03/the\_freemium\_bu/},
urldate = {2.11.2014},
year = {2006}
}
@misc{Winter2009,
abstract = {Alan Hevner is an Eminent Scholar and Professor in the Information Systems and Decision Sciences Department at the University of South Florida, where he holds the Citigroup/Hidden River Chair of Distributed Technology. Dr. Hevner’s areas of research interest include information systems development, software engineering, distributed database systems, health care information systems and telecommunications. He has published more than one hundred and fifty research papers on these topics and has consulted for several Fortune 500 companies. Dr. Hevner has a Ph.D. in Computer Science from Purdue University. He has held faculty positions at the University of Maryland and the University of Minnesota. He recently completed a two-year assignment as a Program Manager at the U.S. National Science Foundation.},
author = {Winter, Robert},
booktitle = {Business \& Information Systems Engineering},
doi = {10.1007/s12599-008-0004-5},
isbn = {1259900800},
issn = {1867-0202},
pages = {126--129},
title = {{Interview with Alan R. Hevner on “Design Science”}},
volume = {1},
year = {2009}
}
@misc{Winter2009a,
abstract = {Alan Hevner is an Eminent Scholar and Professor in the Information Systems and Decision Sciences Department at the University of South Florida, where he holds the Citigroup/Hidden River Chair of Distributed Technology. Dr. Hevner’s areas of research interest include information systems development, software engineering, distributed database systems, health care information systems and telecommunications. He has published more than one hundred and fifty research papers on these topics and has consulted for several Fortune 500 companies. Dr. Hevner has a Ph.D. in Computer Science from Purdue University. He has held faculty positions at the University of Maryland and the University of Minnesota. He recently completed a two-year assignment as a Program Manager at the U.S. National Science Foundation.},
author = {Winter, Robert},
booktitle = {Business \& Information Systems Engineering},
doi = {10.1007/s12599-008-0004-5},
isbn = {1259900800},
issn = {1867-0202},
pages = {126--129},
title = {{Interview with Alan R. Hevner on “Design Science”}},
volume = {1},
year = {2009}
}
